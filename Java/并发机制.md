# 底层实现原理
Java代码在编译后变成Java字节码，字节码被类加载器加载到JVM里，JVM执行字节码，最终需要转化为汇编指令在CPU上执行，
Java中所使用的并发机制依赖于JVM的实现和CPU的指令。

## volatile
volatile是轻量级的synchronized，保证了在多处理器开发中共享变量的可见性。
可见性是当一个线程修改一个共享变量时，另一个线程能读到这个修改的值。

volatile的定义：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他性单独获得这个变量。

volatile的机制：为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存后再进行操作，但操作完不知道何时会写到内存中。
如果声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。
注意：就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。

在多处理器下，为了保证各个处理器的缓存的一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己的缓存的值是不是过期。
当处理器发现缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态。当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存中。

Lock前缀指令会引起处理器缓存写回到内存中。一个处理器的缓存回写到内存会导致其他处理器的缓存无效。

volatile的优化技巧：追加字节到64字节。因为对于英特尔当下的处理器，高速缓存是64个字节宽，不支持部分填充。
因此如果队列的头结点和尾节点不足64字节，它们会读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头尾节点。
当一个处理器试图修改头节点时，会将整个缓存行锁定。如果追加到64字节，避免头节点和尾节点加载到同一个缓存行，使头 ，尾节点在修改时不会互相锁定。

## synchronized
- 对于普通同步方法，锁是当前实例对象
- 对于静态同步方法，锁是当前类的Class对象。
- 对于同步方法块，锁是synchronized括号里配置的对象

实现原理：JVM基于进入和退出Monitor对象来实现方法同步和代码块同步。两者的细节有不同。
monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处。
JVM要保证每个monitorenter必须有对应的monitorexit与之匹配。
任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于被锁定状态。
线程执行到monitorenter指令，将会尝试获取对象所对应的monitor的所有权，即对象锁。


synchronized用的锁是存在Java对象里的。锁有4种状态：无锁状态，偏向锁状态，轻量级锁状态，重量级锁状态。
这几个状态会随着竞争情况逐渐升级。锁可以升级，但不能降级。这可以提高获得锁和释放锁的效率。

## 原子操作
原子操作是不可被中断的一个或一系列的操作。

32位处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。
首先处理器会自动保证基本的内存操作的原子性，然后保证单处理器对同一个缓存行里进行16/32/64位操作是原子的。
但是复杂的内存操作处理器是不能自动保证其原子性的。

处理器提供总线锁和缓存锁定来保证复杂内存操作的原子性。
- 总线锁：处理器提供一个LOCK信号，当一个处理器在总线上输出此信号，其他处理器的请求将被阻塞。开销比较大。
- 缓存锁：内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK信号，
而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性。
缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效。


# 内存模型
两个基本问题：
- 线程之间如何通信
- 线程之间如何同步
通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存，消息传递。
在共享内存模型中，线程之间共享程序的公共状态，通过写读内存中的公共状态进行隐式通信。
在消息内存模型中，线程之间没有公共状态，线程之间必须通过发送消息来显式进行通信。

同步是指程序中用于控制不同线程间操作发生相对顺序的机制。Java用的是共享内存模型。
同步是显式进行的，程序员必须指定某个方法或某段代码需要在线程之间互斥执行。
线程之间的通信是隐式的。

## 模型的抽象结构
在Java中，所有的实例域，静态域和数组元素都储存在堆内存中，堆内存在线程之间共享。
Java线程之间的通信由Java内存模型控制（JMM），JMM决定一个共享变量的写入何时对另一个线程可见。
线程之间的共享变量储存在主内存中，每个线程都有一个私有的本地内存，本地内存中储存了该线程以读/写共享变量的副本。
JMM属于语言级别的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器

如果线程A和线程B之间要通信的话，线程A必须把本地内存A中更新过的共享变量刷新到主内存中，然后线程B到主内存中去读取线程A更新过的共享变量。
线程A必须向线程B发送消息，而且这个通信过程必须要经过主内存。
JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。

现代的处理器使用写缓冲区临时保存向内存写入的数据。
写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。
同时，通过以批处理的方式刷新写入缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总线的占用
但是，每个处理器上的写缓冲区，仅仅对它所在的处理器可见。
也就是说，处理器对内存的读写操作的执行顺序，不一定与内存实际发生的读写顺序一致。

happens-before:在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。
- 程序顺序规则：一个线程中的每个操作，HB于该线程中的任意后续操作
- 监视器锁原则：对一个锁的解锁，HB于随后对这个锁的加锁。
- volatile变量原则：对于一个volatile的域的写，HB语任意后续对这个volatile域的读
- 传递性：A HB于 B ， B HB与 C， 那么A HB于 C

## 重排序
重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。

编译器和处理器在重排序时，会遵守数据依赖性，不会改变存在数据依赖关系的两个操作的执行顺序。
但是这里的数据依赖性仅仅针对单个处理器中执行的操作，不考虑不同处理器之间和不同线程之间的数据依赖性。

不管怎么重排序，程序的执行结果不能改变。
对于实现了重排序的JMM，单线程程序是按照程序的顺序来执行的是一种幻觉。
在计算机中，软硬件的共同目标是：在不改变程序执行结果的前提下，尽可能提高并行度。

当代码中存在控制依赖性，会影响指令序列执行的并行度。编译器和处理器会采用猜测执行来客服控制相关性对并行度的影响。
但是重排序会破坏多线程程序的语义。


## 顺序一致性
数据竞争：在一个线程中写一个变量，在另一个线程读同一个变量，而且写和读没有通过同步来排序。

顺序一致：一个线程中的所有操作必须按程序的顺序来执行。所有线程都只能看到一个单一的操作执行顺序。每个操作都必须原子执行，且立刻对所有线程可见。
在概念上，顺序一致性有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程，同时每一个线程必须按照程序的顺序来执行内存读/写操作。
因此，在任意时间点最多只能有一个线程可以连接到内存。当多个线程并发执行时，所有线程的所有内存操作将串行化。

可是，JMM没有这个保证。未同步程序在JMM中，不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。
当前线程和其他线程看到的操作执行顺序是不一致的。

对于未同步或没有正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值。
为了实现最小安全性，JVM在堆上分配对象时，首先会对内存空间进行清零，然后才会在上面分配对象（并默认初始化）。

JMM并不想保证未同步的程序执行遵守顺序一致性，因为这需要禁止大量的处理器和编译器的优化，极大的损害成本。


## 锁的内存语义
锁可以让临界区互斥执行，是并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。
当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。

当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。

锁释放与volatile写有相同的内存语义；锁获取与volatile读有相同的内存语义。

线程Ａ释放一个锁是线程Ａ向接下来将要获取这个锁的某个线程发出消息。
线程Ｂ获得一个锁是线程Ｂ接收了之前某个线程的消息。
线程Ａ释放锁，随后线程Ｂ获取锁，这个过程是线程Ａ通过主内存向线程Ｂ发送消息。


## happens-before
两个关键因素：
-　程序员希望内存模型易于理解，易于编程，基于强内存模型来编写代码
-　编译器希望内存模型对它们的约束越少越好，来保证尽可能的性能优化

定义：
- 如果操作HB另一个操作,那么第一个操作的执行结果将对第二个操作可见,而且第一个操作的执行顺序排在第二个操作之前.
- 两个操作之间存在HB关系,并不意味着Java平台的具体实现必须要按照HB关系指定的顺序来执行.


# 编程基础
线程作为操作系统调度的最小单元,多个线程能够同时执行,这将显著提升程序性能,在多核环境中表现得更加明显.

## 线程
现代操作系统在运行一个程序时,会为其创建一个进程. 系统调度的最小单元是线程.
在一个进程里可以创建多个线程, 这些线程拥有各自的计数器, 堆栈, 局部变量等属性, 并且能够访问共享的内存变量.
处理器在这些线程上高速切换,让使用者感觉到这些线程在同时执行.

Java程序天生就是多线程程序,main方式一个main的线程.

多线程的好处:
- 更高效的利用多处理器核心
- 更快的响应时间
- 更好的编程模型

## 生命周期

线程随着start方法进行启动,随着run执行完毕,线程也随之终止.

在运行线程之前，首先要构造一个线程对象，线程对象在构造的时候需要提供线程所需要的属性。
一个新构造的线程对象是由其parent线程来进行空间分配的。
一个能够运行的线程对象初始化好了，在堆内存中等待着运行。

中断可以理解为线程的一个标识符属性，表示一个运行中的线程是否被其他线程进行了中断操作。
线程通过检查自身是否被中断来进行响应。中断操作是一种简便的线程间交互方式。
可以利用中断标识或自定义变量来安全地终止线程, 可以使线程在终止时有机会去清理资源.

## 通信
线程开始运行,拥有自己的栈空间.对于同一个对象或者对象的成员,每个线程都有一份拷贝.
因此一个线程看到的变量不一定是最新的.

关键词volatile就是告知程序任何对该变量的访问均需要从共享内存中获取,而对它的改变必须同步刷新回共享内存,它保证所有线程对变量访问的可见性.

关键词synchronized可以修饰方法或者以同步块的形式来进行使用,
确保多个线程在同一个时刻,只能有一个线程处于方法或者同步块,保证了线程对变量访问的可见性和排他性.

任意一个对象都拥有自己的监视器,当这个对象由同步块或者这个对象的同步方法调用时,执行方法的线程必须先获取该对象的监视器才能进入同步块或者同步方法,
而没有获取到监视器的线程将会被阻塞在同步块和同步方法的入口处,进入BOCLKED状态.

等待通知机制,是指线程A调用了对象O的wait进入等待状态,而另一个线程B调用了对象O的notify/notifyAll方法.
线程A收到通知后从对象O的wait方法返回,进而执行后续操作.
该机制确保等待线程从wait方法返回时能够感知到通知线程对变量做出的修改.

如果线程A执行thread.join,含义是当前线程A等待thread线程终止后才从thread.join返回.

ThreadLocal即线程变量,是一个以ThreadLocal对象为键,任意对象为值的储存结构.这个结构被附带在线程上.
因此,一个线程可以根据一个ThreadLocal对象查询到绑定在这个线程上的一个值.



## 线程应用实例

线程池预先创建了若干数量的线程,并且不能由用户直接对线程的创建进行控制,
在这个前提下重复使用固定或较为固定数目的线程来完成任务的执行.
好处是一方面消除了频繁创建和消亡线程的系统资源开销,另一方面,面对过量任务的提交能够平缓的劣化.








